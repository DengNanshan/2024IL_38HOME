{
    "input_dim": 28,
    "output_dim": 2,
    "net_layers": [
      64,
      64
    ],
    "activation": "relu",
    "loss": "mse",
    "learning_rate": 0.001,
    "batch_size": 64,
    "buffer_size": 10000,
    "others": "DiscreteMetaAction",
    "others2": "ContinuousAction"
}